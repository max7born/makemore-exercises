{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHARS = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "\n",
    "  def __init__(self, path: str) -> None:\n",
    "    self.words = open(path, 'r').read().splitlines()\n",
    "    chars = sorted(list(set(''.join(self.words))))\n",
    "    self.ctoi = {c: i+1 for i, c in enumerate(chars)}\n",
    "    self.ctoi['.'] = 0\n",
    "    self.itoc = {i: c for c, i in self.ctoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramExplicitModel:\n",
    "\n",
    "  def __init__(self, n: int, data: Dataset) -> None:\n",
    "    self.n = n\n",
    "    self.data = data\n",
    "\n",
    "  def count(self):\n",
    "    self.counts = torch.zeros(tuple([NUM_CHARS for _ in range(self.n)]), dtype=torch.int32)\n",
    "    for w in self.data.words:\n",
    "      context = [0] * (self.n-1)\n",
    "      for c in w + '.':\n",
    "        ix = self.data.ctoi[c]\n",
    "        indices = tuple(context + [ix])\n",
    "        self.counts[indices] += 1\n",
    "        context = context[1:] + [ix]\n",
    "      \n",
    "    self.P = F.normalize((self.counts+1).float(), p=1, dim=-1)\n",
    "  \n",
    "  def sample(self, generator: torch.Generator, num_samples: int = 1):\n",
    "    for i in range(num_samples):\n",
    "      sample = []\n",
    "      context = [0 for _ in range(self.n-1)]\n",
    "      while True:\n",
    "        ix = torch.multinomial(self.P[tuple(context)], num_samples=1, replacement=True, generator=generator).item()\n",
    "        sample.append(self.data.itoc[ix])\n",
    "        if ix == 0:\n",
    "          break\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "      print(''.join(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramMLPModel:\n",
    "\n",
    "  def __init__(self, n: int, data: Dataset, embed_dim: int) -> None:\n",
    "    self.n = n\n",
    "    self.data = data\n",
    "    self.embed_dim = embed_dim\n",
    "    self.prepare_ds()\n",
    "    self.init_network()\n",
    "\n",
    "  def prepare_ds(self):\n",
    "    # Create train set\n",
    "    self.xs, self.ys = [], []\n",
    "    for w in self.data.words:\n",
    "      context = [0] * (self.n-1) \n",
    "      for c in w + '.':\n",
    "        ix = self.data.ctoi[c]\n",
    "        self.xs.append(context)\n",
    "        self.ys.append(self.data.ctoi[c])\n",
    "        context = context[1:] + [ix]\n",
    "    self.xs = torch.tensor(self.xs)\n",
    "    self.ys = torch.tensor(self.ys)\n",
    "\n",
    "  def init_network(self):\n",
    "    g = torch.Generator().manual_seed(2147483647)\n",
    "    self.C = torch.randn((NUM_CHARS, self.embed_dim), generator=g, requires_grad=True)\n",
    "    # C[xs].shape = (num_data_pairs, context_len, embed_dim)\n",
    "    self.W = torch.randn(((self.n-1)*self.embed_dim, NUM_CHARS), generator=g, requires_grad=True)\n",
    "    self.params = [self.C, self.W]\n",
    "    for p in self.params:\n",
    "      p.requires_grad = True\n",
    "\n",
    "\n",
    "  def train_network(self, num_iters: int, lr: float):\n",
    "    for k in range(num_iters):\n",
    "      # NN forward pass\n",
    "      xenc = self.C[self.xs]\n",
    "      xenc = xenc.view(-1, (self.n-1)*self.embed_dim)\n",
    "      logits = xenc @ self.W             # log counts -> only thing that will change in Transformers\n",
    "      counts = logits.exp()              # equivalent to counts\n",
    "      P = counts / counts.sum(dim=1, keepdims=True)\n",
    "      # last 2 lines: softmax\n",
    "      \n",
    "      # loss: negative llh of probs corresponding to true labels\n",
    "      loss = -P[torch.arange(self.ys.nelement()), self.ys].log().mean() + 0.01*(self.W**2).mean()\n",
    "      \n",
    "      ## NN backward pass\n",
    "      self.W.grad = None       # set grad to 0\n",
    "      loss.backward()\n",
    "      if k%10 == 0:\n",
    "        print(f'Iter {k}, loss {loss.item()}')\n",
    "\n",
    "      self.W.data += -lr*self.W.grad\n",
    "\n",
    "\n",
    "  def sample(self, generator: torch.Generator, num_samples: int):\n",
    "    for i in range(num_samples):\n",
    "      sample = []\n",
    "      context = [0 for _ in range(self.n-1)]\n",
    "      while True:\n",
    "        xenc = self.C[torch.tensor(context)].flatten().unsqueeze(0)\n",
    "        logits = xenc @ self.W\n",
    "        counts = logits.exp()\n",
    "        p = F.normalize(counts.float(), p=1, dim=-1)\n",
    "\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=generator).item()\n",
    "        sample.append(self.data.itoc[ix])\n",
    "        if ix == 0:\n",
    "          break\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "      print(''.join(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "data = Dataset('../../data/names.txt')\n",
    "# model = NGramExplicitModel(n=4, data=data)\n",
    "# model.count()\n",
    "model = NGramMLPModel(2, data, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_network(250, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mor.\n",
      "axwaninaynnnyles.\n",
      "krfjoghkae.\n",
      "anchriqz.\n",
      "rigaraaren.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "model.sample(generator=g, num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21cbe5e4507590016ddf6079d506494e7f2eacb4fe848e3412c5364edd85520f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
