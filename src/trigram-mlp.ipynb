{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxsi\\miniconda3\\envs\\isp\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('../data/names.txt', 'r').read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "ctoi = {c: i+1 for i, c in enumerate(chars)}\n",
    "ctoi['.'] = 0\n",
    "itoc = {i: c for c, i in ctoi.items()}\n",
    "\n",
    "num_chars = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([260179, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train set\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "  w = ['.'] + ['.'] + list(w) + ['.'] + ['.']\n",
    "  for ch1, ch2, ch3 in zip(w, w[1:], w[2:]):\n",
    "    i1, i2, i3= ctoi[ch1], ctoi[ch2], ctoi[ch3]\n",
    "    xs.append((i1, i2))\n",
    "    ys.append(i3)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "num_ex = ys.nelement()\n",
    "\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([260179, 2, 27])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=num_chars).float()\n",
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init NN\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((num_chars, num_chars, num_chars), generator=g, requires_grad=True)\n",
    "num_iters = 100\n",
    "lr = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([260179, 27])\n",
      "2.47672963142395\n",
      "torch.Size([260179, 27])\n",
      "2.4752602577209473\n",
      "torch.Size([260179, 27])\n",
      "2.4738001823425293\n",
      "torch.Size([260179, 27])\n",
      "2.4723501205444336\n",
      "torch.Size([260179, 27])\n",
      "2.470909833908081\n",
      "torch.Size([260179, 27])\n",
      "2.4694790840148926\n",
      "torch.Size([260179, 27])\n",
      "2.468057632446289\n",
      "torch.Size([260179, 27])\n",
      "2.4666452407836914\n",
      "torch.Size([260179, 27])\n",
      "2.4652421474456787\n",
      "torch.Size([260179, 27])\n",
      "2.46384859085083\n",
      "torch.Size([260179, 27])\n",
      "2.462463855743408\n",
      "torch.Size([260179, 27])\n",
      "2.461087703704834\n",
      "torch.Size([260179, 27])\n",
      "2.459721088409424\n",
      "torch.Size([260179, 27])\n",
      "2.4583628177642822\n",
      "torch.Size([260179, 27])\n",
      "2.4570131301879883\n",
      "torch.Size([260179, 27])\n",
      "2.455672025680542\n",
      "torch.Size([260179, 27])\n",
      "2.4543392658233643\n",
      "torch.Size([260179, 27])\n",
      "2.4530153274536133\n",
      "torch.Size([260179, 27])\n",
      "2.4516994953155518\n",
      "torch.Size([260179, 27])\n",
      "2.4503917694091797\n",
      "torch.Size([260179, 27])\n",
      "2.449092388153076\n",
      "torch.Size([260179, 27])\n",
      "2.447801113128662\n",
      "torch.Size([260179, 27])\n",
      "2.4465174674987793\n",
      "torch.Size([260179, 27])\n",
      "2.445241928100586\n",
      "torch.Size([260179, 27])\n",
      "2.4439737796783447\n",
      "torch.Size([260179, 27])\n",
      "2.442713499069214\n",
      "torch.Size([260179, 27])\n",
      "2.4414615631103516\n",
      "torch.Size([260179, 27])\n",
      "2.440216302871704\n",
      "torch.Size([260179, 27])\n",
      "2.438979387283325\n",
      "torch.Size([260179, 27])\n",
      "2.437749147415161\n",
      "torch.Size([260179, 27])\n",
      "2.4365265369415283\n",
      "torch.Size([260179, 27])\n",
      "2.4353108406066895\n",
      "torch.Size([260179, 27])\n",
      "2.434102773666382\n",
      "torch.Size([260179, 27])\n",
      "2.432901620864868\n",
      "torch.Size([260179, 27])\n",
      "2.4317073822021484\n",
      "torch.Size([260179, 27])\n",
      "2.4305202960968018\n",
      "torch.Size([260179, 27])\n",
      "2.429340362548828\n",
      "torch.Size([260179, 27])\n",
      "2.428166627883911\n",
      "torch.Size([260179, 27])\n",
      "2.4270002841949463\n",
      "torch.Size([260179, 27])\n",
      "2.425840377807617\n",
      "torch.Size([260179, 27])\n",
      "2.424686908721924\n",
      "torch.Size([260179, 27])\n",
      "2.4235403537750244\n",
      "torch.Size([260179, 27])\n",
      "2.4223999977111816\n",
      "torch.Size([260179, 27])\n",
      "2.4212663173675537\n",
      "torch.Size([260179, 27])\n",
      "2.4201388359069824\n",
      "torch.Size([260179, 27])\n",
      "2.4190175533294678\n",
      "torch.Size([260179, 27])\n",
      "2.417903184890747\n",
      "torch.Size([260179, 27])\n",
      "2.416794538497925\n",
      "torch.Size([260179, 27])\n",
      "2.415692090988159\n",
      "torch.Size([260179, 27])\n",
      "2.414595365524292\n",
      "torch.Size([260179, 27])\n",
      "2.4135053157806396\n",
      "torch.Size([260179, 27])\n",
      "2.4124207496643066\n",
      "torch.Size([260179, 27])\n",
      "2.411342144012451\n",
      "torch.Size([260179, 27])\n",
      "2.4102694988250732\n",
      "torch.Size([260179, 27])\n",
      "2.4092023372650146\n",
      "torch.Size([260179, 27])\n",
      "2.4081413745880127\n",
      "torch.Size([260179, 27])\n",
      "2.407085657119751\n",
      "torch.Size([260179, 27])\n",
      "2.406035900115967\n",
      "torch.Size([260179, 27])\n",
      "2.404991388320923\n",
      "torch.Size([260179, 27])\n",
      "2.4039528369903564\n",
      "torch.Size([260179, 27])\n",
      "2.4029197692871094\n",
      "torch.Size([260179, 27])\n",
      "2.4018912315368652\n",
      "torch.Size([260179, 27])\n",
      "2.4008688926696777\n",
      "torch.Size([260179, 27])\n",
      "2.3998517990112305\n",
      "torch.Size([260179, 27])\n",
      "2.3988399505615234\n",
      "torch.Size([260179, 27])\n",
      "2.3978333473205566\n",
      "torch.Size([260179, 27])\n",
      "2.396831512451172\n",
      "torch.Size([260179, 27])\n",
      "2.3958351612091064\n",
      "torch.Size([260179, 27])\n",
      "2.3948442935943604\n",
      "torch.Size([260179, 27])\n",
      "2.393857955932617\n",
      "torch.Size([260179, 27])\n",
      "2.392876625061035\n",
      "torch.Size([260179, 27])\n",
      "2.391900062561035\n",
      "torch.Size([260179, 27])\n",
      "2.3909287452697754\n",
      "torch.Size([260179, 27])\n",
      "2.3899619579315186\n",
      "torch.Size([260179, 27])\n",
      "2.389000177383423\n",
      "torch.Size([260179, 27])\n",
      "2.388043165206909\n",
      "torch.Size([260179, 27])\n",
      "2.3870911598205566\n",
      "torch.Size([260179, 27])\n",
      "2.386143684387207\n",
      "torch.Size([260179, 27])\n",
      "2.3852007389068604\n",
      "torch.Size([260179, 27])\n",
      "2.3842623233795166\n",
      "torch.Size([260179, 27])\n",
      "2.383328914642334\n",
      "torch.Size([260179, 27])\n",
      "2.382399320602417\n",
      "torch.Size([260179, 27])\n",
      "2.381474733352661\n",
      "torch.Size([260179, 27])\n",
      "2.380554437637329\n",
      "torch.Size([260179, 27])\n",
      "2.379638433456421\n",
      "torch.Size([260179, 27])\n",
      "2.3787271976470947\n",
      "torch.Size([260179, 27])\n",
      "2.3778202533721924\n",
      "torch.Size([260179, 27])\n",
      "2.3769173622131348\n",
      "torch.Size([260179, 27])\n",
      "2.376018762588501\n",
      "torch.Size([260179, 27])\n",
      "2.375124454498291\n",
      "torch.Size([260179, 27])\n",
      "2.374234199523926\n",
      "torch.Size([260179, 27])\n",
      "2.3733484745025635\n",
      "torch.Size([260179, 27])\n",
      "2.372466564178467\n",
      "torch.Size([260179, 27])\n",
      "2.371588706970215\n",
      "torch.Size([260179, 27])\n",
      "2.3707151412963867\n",
      "torch.Size([260179, 27])\n"
     ]
    }
   ],
   "source": [
    "for k in range(num_iters):\n",
    "  # NN forward pass\n",
    "  # logits = xenc @ W             # log counts -> only thing that will change in Transformers\n",
    "  logits = W[xs[:, 0], xs[:, 1]] \n",
    "  # print(logits.shape)\n",
    "  # matrix mult actually plugs out the i-th row if label is i\n",
    "  counts = logits.exp()         # equivalent to counts\n",
    "  P = counts / counts.sum(dim=1, keepdims=True)\n",
    "  # last 2 lines: softmax\n",
    "  \n",
    "  # loss: negative llh of probs corresponding to true labels\n",
    "  loss = -P[torch.arange(num_ex), ys].log().mean() + 0.01*(W**2).mean()\n",
    "\n",
    "\n",
    "  ## NN backward pass\n",
    "  W.grad = None       # set grad to 0\n",
    "  loss.backward()\n",
    "\n",
    "  print(loss.item())\n",
    "\n",
    "  W.data += -lr*W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnvc.\n",
      "uyallinyqxuznlwckvkovakvfid.\n",
      "maryiuzeqml.\n",
      "odfsfpen.\n",
      "daespeldkqtqkwjkrmgjywov.\n"
     ]
    }
   ],
   "source": [
    "# Sampling\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "num_samples = 5\n",
    "\n",
    "for i in range(num_samples):\n",
    "  sample = []\n",
    "  i1, i2 = 0, 0\n",
    "  while True:\n",
    "    # xenc = F.one_hot(torch.tensor([i1]), num_classes=num_chars).float()\n",
    "    # logits = xenc @ W\n",
    "    logits = W[i1, i2].reshape((1, -1)) \n",
    "    counts = logits.exp()\n",
    "    p = counts / counts.sum(1, keepdims=True)\n",
    "\n",
    "    i3 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    sample.append(itoc[i3])\n",
    "    if i3 == 0:\n",
    "      break\n",
    "    i1, i2 = i2, i3\n",
    "\n",
    "  print(''.join(sample))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21cbe5e4507590016ddf6079d506494e7f2eacb4fe848e3412c5364edd85520f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
